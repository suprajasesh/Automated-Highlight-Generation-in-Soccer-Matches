{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwPwFnRr1mTn",
        "outputId": "53d7c6af-30da-4b96-e790-570527ee8162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYgVwN744nun",
        "outputId": "73d9e22a-dc0d-49ef-fc00-11ba31faf595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (14.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.11)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.4.26)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install torch numpy librosa moviepy av wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gKLRYFJUBWXK"
      },
      "outputs": [],
      "source": [
        "# pip install av"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WQLzpupy4LJk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import librosa\n",
        "from moviepy.editor import VideoFileClip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvVNiAZd268s",
        "outputId": "e1225bbe-b893-4cf6-9dc8-e45455def82c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: wandb 0.19.10\n",
            "Uninstalling wandb-0.19.10:\n",
            "  Successfully uninstalled wandb-0.19.10\n",
            "Collecting wandb\n",
            "  Using cached wandb-0.19.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Using cached wandb-0.19.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "Installing collected packages: wandb\n",
            "Successfully installed wandb-0.19.10\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall wandb -y\n",
        "!pip install wandb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "odZSQ8rZ6qPZ",
        "outputId": "7ee927c0-6b79-4919-e7d2-bab6cb77533f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msupraja2010341\u001b[0m (\u001b[33mfyproject\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250505_143322-xc5k0cv6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fyproject/soccernet_highlights/runs/xc5k0cv6' target=\"_blank\">rebel-nexu-10</a></strong> to <a href='https://wandb.ai/fyproject/soccernet_highlights' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/fyproject/soccernet_highlights' target=\"_blank\">https://wandb.ai/fyproject/soccernet_highlights</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/fyproject/soccernet_highlights/runs/xc5k0cv6' target=\"_blank\">https://wandb.ai/fyproject/soccernet_highlights/runs/xc5k0cv6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/fyproject/soccernet_highlights/runs/xc5k0cv6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b3cfc0092d0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "# Initialize WandB\n",
        "wandb.login(key='add api key')\n",
        "wandb.init(project=\"soccernet_highlights\", config={\n",
        "    \"batch_size\": 4,\n",
        "    \"epochs\": 3,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"video_dim\": 2048,\n",
        "    \"audio_dim\": 20,\n",
        "    \"hidden_dim\": 512\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g1OfQdTLAK66"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50\n",
        "from torchvision.io import read_video\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-qN8huWN0hZB"
      },
      "outputs": [],
      "source": [
        "# Model Definition\n",
        "class TemporalEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n",
        "        self.lstm = nn.LSTM(hidden_dim, hidden_dim // 2, bidirectional=True, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch, time, dim) -> (batch, dim, time)\n",
        "        x = self.conv(x).relu()\n",
        "        x = x.permute(0, 2, 1)  # (batch, time, hidden_dim)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.norm(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hrC9QrR84PGm"
      },
      "outputs": [],
      "source": [
        "class HighlightModel(nn.Module):\n",
        "    def __init__(self, video_dim, audio_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.video_encoder = TemporalEncoder(video_dim, hidden_dim)\n",
        "        self.audio_encoder = TemporalEncoder(audio_dim, hidden_dim)\n",
        "        self.fusion = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.scorer = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, video, audio, event_timestamps):\n",
        "        event_timestamps=event_timestamps.long()\n",
        "        video_features = self.video_encoder(video)  # (batch, time, hidden)\n",
        "        audio_features = self.audio_encoder(audio)  # (batch, time, hidden)\n",
        "        fused_features = torch.cat([video_features, audio_features], dim=-1)  # (batch, time, hidden*2)\n",
        "        fused_features = self.fusion(fused_features).relu()  # (batch, time, hidden)\n",
        "        event_features = fused_features[torch.arange(fused_features.size(0))[:, None], event_timestamps]\n",
        "        scores = self.scorer(event_features).sigmoid()  # (batch, num_events, 1)\n",
        "        return scores.squeeze(-1)  # (batch, num_events)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0_H9bngC4Ub7"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "class SoccerNetDataset(Dataset):\n",
        "    def __init__(self, data_dir, split_file, feature_rate=1, max_events=50, device=\"cuda\",top=10):\n",
        "        self.data_dir = data_dir\n",
        "        self.feature_rate = feature_rate\n",
        "        self.max_events = max_events\n",
        "        self.device = device\n",
        "        self.game_dirs = self._load_games(split_file)[:top]  # Limit to 10 games as per original\n",
        "        # self.top=top\n",
        "\n",
        "    def _load_games(self, split_file):\n",
        "        with open(split_file) as f:\n",
        "            game_dirs = json.load(f)  # List of absolute game folder paths\n",
        "        valid_dirs = [d for d in game_dirs if os.path.exists(d)]\n",
        "        if len(valid_dirs) < len(game_dirs):\n",
        "            print(f\"Warning: {len(game_dirs) - len(valid_dirs)} game directories not found\")\n",
        "        return valid_dirs\n",
        "\n",
        "    def _load_video_features(self, game_dir):\n",
        "        feature_files = sorted(glob.glob(os.path.join(game_dir, \"*_ResNET_TF2.npy\")))\n",
        "        if len(feature_files) < 2:\n",
        "            raise FileNotFoundError(f\"Expected 1_ResNET_TF2.npy and 2_ResNET_TF2.npy in {game_dir}, found {len(feature_files)}\")\n",
        "        features1 = np.load(feature_files[0])\n",
        "        features2 = np.load(feature_files[1])\n",
        "        video_features = np.concatenate([features1, features2], axis=0)  # (T, 2048)\n",
        "        return torch.tensor(video_features, dtype=torch.float32).to(self.device)\n",
        "\n",
        "    def _load_audio_features(self, game_dir, target_length):\n",
        "        audio_files = sorted(glob.glob(os.path.join(game_dir, \"*_224p.wav\")))\n",
        "        if len(audio_files) < 2:\n",
        "            raise FileNotFoundError(f\"Expected 1_224p.wav and 2_224p.wav in {game_dir}, found {len(audio_files)}\")\n",
        "        mfccs = []\n",
        "        audio_signals = []\n",
        "        sr = None\n",
        "        for audio_file in audio_files:\n",
        "            y, sr = librosa.load(audio_file, sr=None)\n",
        "            hop_length = int(sr / self.feature_rate)\n",
        "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20, hop_length=hop_length)\n",
        "            mfccs.append(mfcc.T)\n",
        "            audio_signals.append(y)\n",
        "        audio_features = np.concatenate(mfccs, axis=0)\n",
        "        audio_features = librosa.util.fix_length(audio_features.T, size=target_length, axis=1).T\n",
        "        audio_signal = np.concatenate(audio_signals)\n",
        "        return (torch.tensor(audio_features, dtype=torch.float32).to(self.device),\n",
        "                audio_signal, sr)\n",
        "\n",
        "    def _parse_game_time(self, game_time):\n",
        "        \"\"\"Convert gameTime (e.g., '1 - 00:41') to seconds.\"\"\"\n",
        "        half, time_str = game_time.split(\" - \")\n",
        "        minutes, seconds = map(int, time_str.split(\":\"))\n",
        "        total_seconds = minutes * 60 + seconds\n",
        "        return int(half), total_seconds\n",
        "\n",
        "    def _load_event_timestamps(self, game_dir, video_length, audio_signal, sr):\n",
        "        annotation_file = os.path.join(game_dir, \"Labels-v2.json\")\n",
        "        if not os.path.exists(annotation_file):\n",
        "            raise FileNotFoundError(f\"No Labels-v2.json found in {game_dir}\")\n",
        "        with open(annotation_file) as f:\n",
        "            data = json.load(f)\n",
        "        events = data.get(\"annotations\", [])\n",
        "        half1_duration = self._get_half1_duration(os.path.join(game_dir, \"1_224p.mp4\"))\n",
        "        half1_duration_frames = int(half1_duration * self.feature_rate)\n",
        "\n",
        "        timestamps = []\n",
        "        audio_scores = []\n",
        "        window_seconds = 5  # ±5 seconds window for audio energy\n",
        "        window_samples = int(window_seconds * sr)\n",
        "\n",
        "        for event in events:\n",
        "            half, time_seconds = self._parse_game_time(event[\"gameTime\"])\n",
        "            timestamp = int(time_seconds * self.feature_rate)\n",
        "            if half == 2:\n",
        "                timestamp += half1_duration_frames\n",
        "            if timestamp < video_length:\n",
        "                timestamps.append(timestamp)\n",
        "                # Compute audio energy in ±5s window\n",
        "                audio_time = time_seconds + (half1_duration if half == 2 else 0)\n",
        "                center_sample = int(audio_time * sr)\n",
        "                start_sample = max(0, center_sample - window_samples)\n",
        "                end_sample = min(len(audio_signal), center_sample + window_samples)\n",
        "                window = audio_signal[start_sample:end_sample]\n",
        "                rms = librosa.feature.rms(y=window, frame_length=2048, hop_length=512)\n",
        "                score = np.mean(rms) if rms.size > 0 else 0.0\n",
        "                audio_scores.append(score)\n",
        "\n",
        "        # Normalize audio scores to [0, 1]\n",
        "        if audio_scores:\n",
        "            audio_scores = np.array(audio_scores)\n",
        "            min_score, max_score = audio_scores.min(), audio_scores.max()\n",
        "            if max_score > min_score:\n",
        "                audio_scores = (audio_scores - min_score) / (max_score - min_score)\n",
        "            else:\n",
        "                audio_scores = np.zeros_like(audio_scores)\n",
        "\n",
        "        num_events = len(timestamps)\n",
        "        if num_events == 0:\n",
        "            timestamps = [0]\n",
        "            audio_scores = [0.0]\n",
        "            num_events = 0\n",
        "        if num_events > self.max_events:\n",
        "            timestamps = timestamps[:self.max_events]\n",
        "            audio_scores = audio_scores[:self.max_events]\n",
        "            num_events = self.max_events\n",
        "        else:\n",
        "            timestamps += [0] * (self.max_events - num_events)\n",
        "            audio_scores += [0.0] * (self.max_events - num_events)\n",
        "\n",
        "        return (torch.tensor(timestamps, dtype=torch.long),\n",
        "                torch.tensor(audio_scores, dtype=torch.float32),\n",
        "                num_events)\n",
        "\n",
        "    def _get_half1_duration(self, video_path):\n",
        "        try:\n",
        "            video = VideoFileClip(video_path)\n",
        "            duration = video.duration\n",
        "            video.close()\n",
        "            return duration\n",
        "        except Exception:\n",
        "            return 2700  # Default: 45 minutes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.game_dirs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        game_dir = self.game_dirs[idx]\n",
        "        try:\n",
        "            video_tensor = self._load_video_features(game_dir)\n",
        "            audio_tensor, audio_signal, sr = self._load_audio_features(game_dir, video_tensor.shape[0])\n",
        "            timestamps, scores, num_events = self._load_event_timestamps(game_dir, video_tensor.shape[0], audio_signal, sr)\n",
        "            return {\n",
        "                \"video\": video_tensor,\n",
        "                \"audio\": audio_tensor,\n",
        "                \"timestamps\": timestamps.to(self.device),\n",
        "                \"scores\": scores.to(self.device),\n",
        "                \"num_events\": num_events\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {game_dir} due to error: {e}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UBmmGyO1xddO"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def custom_collate(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    if not batch:\n",
        "        return None\n",
        "\n",
        "    # Convert each item to torch.Tensor with consistent dtype\n",
        "    videos = [b[\"video\"].clone().detach() for b in batch]\n",
        "    audios = [b[\"audio\"].clone().detach() for b in batch]\n",
        "    timestamps = [b[\"timestamps\"].clone().detach().long() for b in batch]\n",
        "    scores = [b[\"scores\"].clone().detach() for b in batch]  # (Ti,)\n",
        "    num_events = [b[\"num_events\"] for b in batch]\n",
        "\n",
        "    # Pad all sequences to max length in batch\n",
        "    padded_videos = pad_sequence(videos, batch_first=True)        # (B, T_max, 2048)\n",
        "    padded_audios = pad_sequence(audios, batch_first=True)        # (B, T_max, 20)\n",
        "    padded_timestamps = pad_sequence(timestamps, batch_first=True) # (B, T_max)\n",
        "    padded_scores = pad_sequence(scores, batch_first=True)         # (B, T_max)\n",
        "\n",
        "    return {\n",
        "        \"video\": padded_videos,\n",
        "        \"audio\": padded_audios,\n",
        "        \"timestamps\": padded_timestamps,\n",
        "        \"scores\": padded_scores,\n",
        "        \"num_events\": num_events\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5fQHR1tA4YjN"
      },
      "outputs": [],
      "source": [
        "def train_model(data_dir, train_split, valid_split, batch_size=1, epochs=10, lr=1e-3, device=\"cuda\"):\n",
        "    # Initialize datasets and dataloaders\n",
        "    train_dataset = SoccerNetDataset(data_dir, train_split, device=device,top=50)\n",
        "    val_dataset = SoccerNetDataset(data_dir, valid_split, device=device,top=10)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=custom_collate)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=custom_collate)\n",
        "\n",
        "    print(f\"Training dataset size: {len(train_dataset)} games\")\n",
        "    print(f\"Validation dataset size: {len(val_dataset)} games\")\n",
        "\n",
        "    # Initialize model\n",
        "    model = HighlightModel(video_dim=2048, audio_dim=20, hidden_dim=512).to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    print(\"Started training\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_batches = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            if batch is None:\n",
        "                continue\n",
        "            video = batch[\"video\"].to(device)             # (B, T, 2048)\n",
        "            audio = batch[\"audio\"].to(device)             # (B, T, 20)\n",
        "            timestamps = batch[\"timestamps\"].to(device)   # (B, T)\n",
        "            scores = batch[\"scores\"].to(device)           # (B, T)\n",
        "            num_events = batch[\"num_events\"]              # List of actual lengths per sample\n",
        "\n",
        "            if all(n == 0 for n in num_events):\n",
        "                continue\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred_scores = model(video, audio, timestamps) # (B, T)\n",
        "\n",
        "            loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
        "            valid_samples = 0\n",
        "            for i in range(len(num_events)):\n",
        "                if num_events[i] > 0:\n",
        "                    valid_scores = pred_scores[i, :num_events[i]]\n",
        "                    valid_gt = scores[i, :num_events[i]]\n",
        "                    loss = loss + criterion(valid_scores, valid_gt)\n",
        "\n",
        "                    # Accuracy\n",
        "                    pred_labels = (valid_scores >= 0.5).float()\n",
        "                    train_correct += (pred_labels == valid_gt).float().sum().item()\n",
        "                    train_total += valid_gt.numel()\n",
        "\n",
        "                    valid_samples += 1\n",
        "\n",
        "            if valid_samples > 0:\n",
        "                loss = loss / valid_samples\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "                train_batches += 1\n",
        "                # train_accuracy = train_correct / train_total if train_total > 0 else 0.0\n",
        "                wandb.log({\"batch_train_loss\": loss.item()})\n",
        "\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(train_loader)}, \"\n",
        "                      f\"Train Loss: {loss.item():.4f}\")\n",
        "\n",
        "        train_loss = train_loss / train_batches if train_batches > 0 else 0.0\n",
        "        # train_accuracy = train_correct / train_total if train_total > 0 else 0.0\n",
        "\n",
        "        print(\"Started validation\")\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_mae = 0.0\n",
        "        val_count = 0\n",
        "        val_batches = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_loader):\n",
        "                if batch is None:\n",
        "                    continue\n",
        "                video = batch[\"video\"].to(device)\n",
        "                audio = batch[\"audio\"].to(device)\n",
        "                timestamps = batch[\"timestamps\"].to(device)\n",
        "                scores = batch[\"scores\"].to(device)\n",
        "                num_events = batch[\"num_events\"]\n",
        "\n",
        "                if all(n == 0 for n in num_events):\n",
        "                    continue\n",
        "\n",
        "                pred_scores = model(video, audio, timestamps)\n",
        "                loss = torch.tensor(0.0, device=device)\n",
        "                for i in range(len(num_events)):\n",
        "                    if num_events[i] > 0:\n",
        "                        valid_scores = pred_scores[i, :num_events[i]]\n",
        "                        valid_gt = scores[i, :num_events[i]]\n",
        "                        loss = loss + criterion(valid_scores, valid_gt)\n",
        "\n",
        "                        val_mae += torch.mean(torch.abs(valid_scores - valid_gt)).item()\n",
        "                        val_count += 1\n",
        "\n",
        "                        pred_labels = (valid_scores >= 0.5).float()\n",
        "                        val_correct += (pred_labels == valid_gt).float().sum().item()\n",
        "                        val_total += valid_gt.numel()\n",
        "\n",
        "                if val_count > 0:\n",
        "                    val_loss += (loss / len(num_events)).item()\n",
        "                    val_batches += 1\n",
        "                    # val_accuracy = val_correct / val_total if val_total > 0 else 0.0\n",
        "                    print(f\"Epoch {epoch+1}/{epochs}, Validation Batch {batch_idx+1}/{len(val_loader)}, \"\n",
        "                          f\"Val Loss: {(loss / len(num_events)).item():.4f}, Val MAE: {val_mae:.4f}\")\n",
        "\n",
        "        val_loss = val_loss / val_batches if val_batches > 0 else 0.0\n",
        "        val_mae = val_mae / val_count if val_count > 0 else 0.0\n",
        "        # val_accuracy = val_correct / val_total if val_total > 0 else 0.0\n",
        "\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            # \"train_accuracy\": train_accuracy,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_mae\": val_mae,\n",
        "            # \"val_accuracy\": val_accuracy\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f},\"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), \"highlight_model.pth\")\n",
        "    wandb.save(\"highlight_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0rRhkYb4b-w",
        "outputId": "4d5f14bf-84f2-4247-cb47-25aaab26648c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset size: 50 games\n",
            "Validation dataset size: 10 games\n",
            "Started training\n",
            "Epoch 1/3, Batch 1/13, Train Loss: 0.6910\n",
            "Epoch 1/3, Batch 2/13, Train Loss: 1.1279\n",
            "Epoch 1/3, Batch 3/13, Train Loss: 1.1055\n",
            "Epoch 1/3, Batch 4/13, Train Loss: 0.7002\n",
            "Epoch 1/3, Batch 5/13, Train Loss: 0.7086\n",
            "Epoch 1/3, Batch 6/13, Train Loss: 0.7347\n",
            "Epoch 1/3, Batch 7/13, Train Loss: 0.6927\n",
            "Epoch 1/3, Batch 8/13, Train Loss: 0.7411\n",
            "Epoch 1/3, Batch 9/13, Train Loss: 0.6361\n",
            "Epoch 1/3, Batch 10/13, Train Loss: 0.7127\n",
            "Epoch 1/3, Batch 11/13, Train Loss: 0.7064\n",
            "Epoch 1/3, Batch 12/13, Train Loss: 0.6978\n",
            "Epoch 1/3, Batch 13/13, Train Loss: 0.6933\n",
            "Started validation\n",
            "Epoch 1/3, Validation Batch 1/3, Val Loss: 0.6995, Val MAE: 0.8144\n",
            "Epoch 1/3, Validation Batch 2/3, Val Loss: 0.7103, Val MAE: 1.5820\n",
            "Epoch 1/3, Validation Batch 3/3, Val Loss: 0.7288, Val MAE: 2.0801\n",
            "Epoch 1/3, Train Loss: 0.7652,Val Loss: 0.7129, Val MAE: 0.2080\n",
            "Epoch 2/3, Batch 1/13, Train Loss: 0.7028\n",
            "Epoch 2/3, Batch 2/13, Train Loss: 0.6944\n",
            "Epoch 2/3, Batch 3/13, Train Loss: 0.6938\n",
            "Epoch 2/3, Batch 4/13, Train Loss: 0.6857\n",
            "Epoch 2/3, Batch 5/13, Train Loss: 0.7172\n",
            "Epoch 2/3, Batch 6/13, Train Loss: 0.6783\n",
            "Epoch 2/3, Batch 7/13, Train Loss: 0.7208\n",
            "Epoch 2/3, Batch 8/13, Train Loss: 0.7255\n",
            "Epoch 2/3, Batch 9/13, Train Loss: 0.6948\n",
            "Epoch 2/3, Batch 10/13, Train Loss: 0.6984\n",
            "Epoch 2/3, Batch 11/13, Train Loss: 0.7080\n",
            "Epoch 2/3, Batch 12/13, Train Loss: 0.7095\n",
            "Epoch 2/3, Batch 13/13, Train Loss: 0.6930\n",
            "Started validation\n",
            "Epoch 2/3, Validation Batch 1/3, Val Loss: 0.6916, Val MAE: 0.7761\n",
            "Epoch 2/3, Validation Batch 2/3, Val Loss: 0.6761, Val MAE: 1.4135\n",
            "Epoch 2/3, Validation Batch 3/3, Val Loss: 0.6589, Val MAE: 1.7835\n",
            "Epoch 2/3, Train Loss: 0.7017,Val Loss: 0.6755, Val MAE: 0.1783\n",
            "Epoch 3/3, Batch 1/13, Train Loss: 0.6871\n",
            "Epoch 3/3, Batch 2/13, Train Loss: 0.6490\n",
            "Epoch 3/3, Batch 3/13, Train Loss: 0.7342\n",
            "Epoch 3/3, Batch 4/13, Train Loss: 0.7466\n",
            "Epoch 3/3, Batch 5/13, Train Loss: 0.6862\n",
            "Epoch 3/3, Batch 6/13, Train Loss: 0.6847\n",
            "Epoch 3/3, Batch 7/13, Train Loss: 0.6914\n",
            "Epoch 3/3, Batch 8/13, Train Loss: 0.6951\n",
            "Epoch 3/3, Batch 9/13, Train Loss: 0.6970\n",
            "Epoch 3/3, Batch 10/13, Train Loss: 0.6907\n",
            "Epoch 3/3, Batch 11/13, Train Loss: 0.7090\n",
            "Epoch 3/3, Batch 12/13, Train Loss: 0.6927\n",
            "Epoch 3/3, Batch 13/13, Train Loss: 0.6921\n",
            "Started validation\n",
            "Epoch 3/3, Validation Batch 1/3, Val Loss: 0.6933, Val MAE: 0.7780\n",
            "Epoch 3/3, Validation Batch 2/3, Val Loss: 0.6714, Val MAE: 1.3945\n",
            "Epoch 3/3, Validation Batch 3/3, Val Loss: 0.6474, Val MAE: 1.7435\n",
            "Epoch 3/3, Train Loss: 0.6966,Val Loss: 0.6707, Val MAE: 0.1743\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"/content/drive/MyDrive/soccernet\"  # Update with your path\n",
        "    train_split = os.path.join(data_dir, \"train.json\")\n",
        "    valid_split = os.path.join(data_dir, \"valid.json\")\n",
        "    # print(train_split)\n",
        "    train_model(data_dir, train_split, valid_split, batch_size=4, epochs=3, lr=1e-3, device=\"cuda\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
